{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Install all the depedencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hwv3bKJiw4zU",
        "outputId": "6ebeafec-30e5-41d6-a1b3-1512379e9b32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in c:\\users\\shyamalan kannan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.28.2)\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\users\\shyamalan kannan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (4.12.2)\n",
            "Requirement already satisfied: nltk in c:\\users\\shyamalan kannan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (3.8.1)\n",
            "Requirement already satisfied: pandas in c:\\users\\shyamalan kannan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.5.3)\n",
            "Requirement already satisfied: openpyxl in c:\\users\\shyamalan kannan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (3.1.2)\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.1.2-py3-none-any.whl (153 kB)\n",
            "     ---------------------------------------- 0.0/153.0 kB ? eta -:--:--\n",
            "     -------- ------------------------------- 30.7/153.0 kB ? eta -:--:--\n",
            "     -------- ------------------------------- 30.7/153.0 kB ? eta -:--:--\n",
            "     --------- --------------------------- 41.0/153.0 kB 326.8 kB/s eta 0:00:01\n",
            "     --------- --------------------------- 41.0/153.0 kB 326.8 kB/s eta 0:00:01\n",
            "     -------------- ---------------------- 61.4/153.0 kB 272.3 kB/s eta 0:00:01\n",
            "     ------------------- ----------------- 81.9/153.0 kB 305.0 kB/s eta 0:00:01\n",
            "     ------------------- ----------------- 81.9/153.0 kB 305.0 kB/s eta 0:00:01\n",
            "     ---------------------- -------------- 92.2/153.0 kB 238.1 kB/s eta 0:00:01\n",
            "     -------------------------- --------- 112.6/153.0 kB 261.9 kB/s eta 0:00:01\n",
            "     -------------------------- --------- 112.6/153.0 kB 261.9 kB/s eta 0:00:01\n",
            "     ---------------------------- ------- 122.9/153.0 kB 225.3 kB/s eta 0:00:01\n",
            "     ---------------------------- ------- 122.9/153.0 kB 225.3 kB/s eta 0:00:01\n",
            "     ---------------------------- ------- 122.9/153.0 kB 225.3 kB/s eta 0:00:01\n",
            "     ---------------------------- ------- 122.9/153.0 kB 225.3 kB/s eta 0:00:01\n",
            "     ---------------------------- ------- 122.9/153.0 kB 225.3 kB/s eta 0:00:01\n",
            "     ---------------------------- ------- 122.9/153.0 kB 225.3 kB/s eta 0:00:01\n",
            "     ---------------------------- ------- 122.9/153.0 kB 225.3 kB/s eta 0:00:01\n",
            "     ---------------------------- ------- 122.9/153.0 kB 225.3 kB/s eta 0:00:01\n",
            "     ---------------------------- ------- 122.9/153.0 kB 225.3 kB/s eta 0:00:01\n",
            "     ---------------------------- ------- 122.9/153.0 kB 225.3 kB/s eta 0:00:01\n",
            "     ---------------------------- ------- 122.9/153.0 kB 225.3 kB/s eta 0:00:01\n",
            "     ---------------------------- ------- 122.9/153.0 kB 225.3 kB/s eta 0:00:01\n",
            "     ---------------------------- ------- 122.9/153.0 kB 225.3 kB/s eta 0:00:01\n",
            "     ---------------------------- ------- 122.9/153.0 kB 225.3 kB/s eta 0:00:01\n",
            "     --------------------------------- -- 143.4/153.0 kB 119.9 kB/s eta 0:00:01\n",
            "     --------------------------------- -- 143.4/153.0 kB 119.9 kB/s eta 0:00:01\n",
            "     ------------------------------------ 153.0/153.0 kB 117.1 kB/s eta 0:00:00\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shyamalan kannan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shyamalan kannan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests) (2.1.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\shyamalan kannan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shyamalan kannan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests) (2022.12.7)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\shyamalan kannan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from beautifulsoup4) (2.4.1)\n",
            "Requirement already satisfied: joblib in c:\\users\\shyamalan kannan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\shyamalan kannan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: click in c:\\users\\shyamalan kannan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk) (8.1.6)\n",
            "Requirement already satisfied: tqdm in c:\\users\\shyamalan kannan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\shyamalan kannan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shyamalan kannan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\shyamalan kannan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (1.23.1)\n",
            "Requirement already satisfied: et-xmlfile in c:\\users\\shyamalan kannan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openpyxl) (1.1.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\shyamalan kannan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\shyamalan kannan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from click->nltk) (0.4.6)\n",
            "Installing collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.1.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 23.2.1\n",
            "[notice] To update, run: C:\\Users\\Shyamalan Kannan\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install requests beautifulsoup4 nltk pandas openpyxl xlsxwriter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Importing all the required libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ih5OwZxS6gWZ",
        "outputId": "2d532c67-2306-4d44-92fe-95ddfd7764ff"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to C:\\Users\\Shyamalan\n",
            "[nltk_data]     Kannan\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to C:\\Users\\Shyamalan\n",
            "[nltk_data]     Kannan\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZg95gn3wVq-",
        "outputId": "3224bd1b-1848-4552-8265-73869398ad0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error: 404 Client Error: Not Found for url: https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/\n",
            "Error: 404 Client Error: Not Found for url: https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/\n",
            "Error: 404 Client Error: Not Found for url: https://insights.blackcoffer.com/ensuring-growth-through-insurance-technology/\n",
            "Output data saved to Output Data Structure.xlsx\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import xlsxwriter\n",
        "def retrieve_text_from_url(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        title = soup.find('title').get_text() if soup.find('title') else ''\n",
        "        paragraphs = soup.find_all('p')\n",
        "        article_text = ' '.join(p.get_text() for p in paragraphs)\n",
        "\n",
        "        return title, article_text\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(\"Error:\", e)\n",
        "        return None, None\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = word_tokenize(text)\n",
        "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "    filtered_text = ' '.join(filtered_words)\n",
        "    return filtered_text\n",
        "\n",
        "def calculate_sentiment_percentage(text, positive_words, negative_words):\n",
        "    words = text.lower().split()\n",
        "    total_words = len(words)\n",
        "    positive_count = sum(1 for word in words if word in positive_words)\n",
        "    negative_count = sum(1 for word in words if word in negative_words)\n",
        "    positive_percentage = (positive_count / total_words) * 100\n",
        "    negative_percentage = (negative_count / total_words) * 100\n",
        "    return positive_percentage, negative_percentage\n",
        "\n",
        "def calculate_polarity_score(positive_percentage, negative_percentage):\n",
        "    return positive_percentage - negative_percentage\n",
        "\n",
        "def calculate_subjectivity_score(positive_percentage, negative_percentage):\n",
        "    return positive_percentage + negative_percentage\n",
        "\n",
        "def calculate_avg_sentence_length(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    total_words = sum(len(word_tokenize(sentence)) for sentence in sentences)\n",
        "    total_sentences = len(sentences)\n",
        "    return total_words / total_sentences if total_sentences > 0 else 0\n",
        "\n",
        "def calculate_percentage_complex_words(text):\n",
        "    words = word_tokenize(text)\n",
        "    complex_word_count = sum(1 for word in words if len(word) > 6)  # Example threshold for complexity\n",
        "    total_words = len(words)\n",
        "    return (complex_word_count / total_words) * 100 if total_words > 0 else 0\n",
        "\n",
        "def calculate_fog_index(avg_sentence_length, percentage_complex_words):\n",
        "    return 0.4 * (avg_sentence_length + percentage_complex_words)\n",
        "\n",
        "def calculate_avg_words_per_sentence(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    total_sentences = len(sentences)\n",
        "    total_words = sum(len(word_tokenize(sentence)) for sentence in sentences)\n",
        "    return total_words / total_sentences if total_sentences > 0 else 0\n",
        "\n",
        "def calculate_complex_word_count(text):\n",
        "    words = word_tokenize(text)\n",
        "    complex_word_count = sum(1 for word in words if len(word) > 6)  # Example threshold for complexity\n",
        "    return complex_word_count\n",
        "\n",
        "def calculate_word_count(text):\n",
        "    words = word_tokenize(text)\n",
        "    return len(words)\n",
        "\n",
        "def count_syllables(word):\n",
        "    vowels = \"aeiouy\"\n",
        "    count = 0\n",
        "    if word[0] in vowels:\n",
        "        count += 1\n",
        "    for index in range(1, len(word)):\n",
        "        if word[index] in vowels and word[index - 1] not in vowels:\n",
        "            count += 1\n",
        "    if word.endswith(\"e\"):\n",
        "        count -= 1\n",
        "    if count == 0:\n",
        "        count = 1\n",
        "    return count\n",
        "\n",
        "def calculate_syllable_per_word(text):\n",
        "    words = word_tokenize(text)\n",
        "    total_syllables = sum(count_syllables(word) for word in words)\n",
        "    total_words = len(words)\n",
        "    return total_syllables / total_words if total_words > 0 else 0\n",
        "\n",
        "def calculate_personal_pronouns(text):\n",
        "    personal_pronouns = ['i', 'me', 'my', 'mine', 'we', 'us', 'our', 'ours', 'you', 'your', 'yours', 'he', 'him', 'his', 'she', 'her', 'hers', 'it', 'its', 'they', 'them', 'their', 'theirs']\n",
        "    words = word_tokenize(text)\n",
        "    personal_pronoun_count = sum(1 for word in words if word.lower() in personal_pronouns)\n",
        "    return personal_pronoun_count\n",
        "\n",
        "def calculate_avg_word_length(text):\n",
        "    words = word_tokenize(text)\n",
        "    total_characters = sum(len(word) for word in words)\n",
        "    total_words = len(words)\n",
        "    return total_characters / total_words if total_words > 0 else 0\n",
        "\n",
        "input_file_path = 'Input.xlsx'\n",
        "output_data_file = 'Output Data Structure.xlsx'\n",
        "output_folder = 'extracted_articles'\n",
        "\n",
        "positive_words = load_word_list('positive-words.txt')\n",
        "negative_words = load_word_list('negative-words.txt')\n",
        "\n",
        "data_frame = pd.read_excel(input_file_path)\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "output_data = []\n",
        "\n",
        "for index, row in data_frame.iterrows():\n",
        "    url = row['URL']\n",
        "    url_id = re.sub(r'\\W+', '', url)\n",
        "\n",
        "    title, article_text = retrieve_text_from_url(url)\n",
        "\n",
        "    if title and article_text:\n",
        "        article_text = remove_stopwords(article_text)\n",
        "        positive_percentage, negative_percentage = calculate_sentiment_percentage(article_text, positive_words, negative_words)\n",
        "        polarity_score = calculate_polarity_score(positive_percentage, negative_percentage)\n",
        "        subjectivity_score = calculate_subjectivity_score(positive_percentage, negative_percentage)\n",
        "        avg_sentence_length = calculate_avg_sentence_length(article_text)\n",
        "        percentage_complex_words = calculate_percentage_complex_words(article_text)\n",
        "        fog_index = calculate_fog_index(avg_sentence_length, percentage_complex_words)\n",
        "        avg_words_per_sentence = calculate_avg_words_per_sentence(article_text)\n",
        "        complex_word_count = calculate_complex_word_count(article_text)\n",
        "        word_count = calculate_word_count(article_text)\n",
        "        syllable_per_word = calculate_syllable_per_word(article_text)\n",
        "        personal_pronouns = calculate_personal_pronouns(article_text)\n",
        "        avg_word_length = calculate_avg_word_length(article_text)\n",
        "\n",
        "        output_data.append({\n",
        "            'URL': url,\n",
        "            'POSITIVE SCORE': positive_percentage,\n",
        "            'NEGATIVE SCORE': negative_percentage,\n",
        "            'POLARITY SCORE': polarity_score,\n",
        "            'SUBJECTIVITY SCORE': subjectivity_score,\n",
        "            'AVG SENTENCE LENGTH': avg_sentence_length,\n",
        "            'PERCENTAGE OF COMPLEX WORDS': percentage_complex_words,\n",
        "            'FOG INDEX': fog_index,\n",
        "            'AVG NUMBER OF WORDS PER SENTENCE': avg_words_per_sentence,\n",
        "            'COMPLEX WORD COUNT' : complex_word_count,\n",
        "            'WORD COUNT' : word_count,\n",
        "            'SYLLABLE PER WORD' : syllable_per_word,\n",
        "            'PERSONAL PRONOUNS' : personal_pronouns,\n",
        "            'AVG WORD LENGTH' : avg_word_length\n",
        "        })\n",
        "        \n",
        "workbook = xlsxwriter.Workbook(output_data_file)\n",
        "worksheet = workbook.add_worksheet()\n",
        "hyperlink_format = workbook.add_format({'color': 'blue', 'underline': 1})\n",
        "worksheet.set_column('A:A', 15)\n",
        "worksheet.write_url('A1', output_data_file, hyperlink_format)\n",
        "workbook.close()\n",
        "\n",
        "output_data_frame = pd.DataFrame(output_data)\n",
        "output_data_frame.to_excel(output_data_file, index=False)\n",
        "print(f\"Output data saved to {output_data_file}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
